#!/bin/bash

echo "ğŸš€ Setting up DBot..."

# Check requirements
command -v docker >/dev/null 2>&1 || { echo "âŒ Docker required"; exit 1; }
command -v ollama >/dev/null 2>&1 || { echo "âŒ Ollama required"; exit 1; }
command -v python3 >/dev/null 2>&1 || { echo "âŒ Python3 required"; exit 1; }

# Start Redis
echo "ğŸ“¦ Starting Redis Stack..."
docker run -d --name redis-stack -p 6379:6379 redis/redis-stack-server 2>/dev/null || echo "âœ… Redis already running"

# Install Python deps
echo "ğŸ Installing Python dependencies..."
pip install -r requirements.txt > /dev/null 2>&1

# Start MCP server in background
echo "ğŸ”§ Starting DBot MCP Server..."
node src/mcp_server.js &
MCP_PID=$!
echo "âœ… DBot MCP Server running (PID: $MCP_PID)"

# Download models with progress feedback
echo "ğŸ“¥ Downloading LLM models (this will take a while)..."
echo "   - Downloading qwen2.5-vl:32b (vision model)..."
ollama pull qwen2.5-vl:32b > /dev/null 2>&1 &
QWEN_PID=$!

echo "   - Downloading deepseek-r1:1.5b (reasoning model)..."
ollama pull deepseek-r1:1.5b > /dev/null 2>&1 &
DEEPSEEK_PID=$!

echo "   - Downloading devstral:latest (coding model)..."
ollama pull devstral:latest > /dev/null 2>&1 &
DEVSTRAL_PID=$!

# Wait for models with progress
wait $QWEN_PID && echo "âœ… Vision model downloaded"
wait $DEEPSEEK_PID && echo "âœ… Reasoning model downloaded"  
wait $DEVSTRAL_PID && echo "âœ… Coding model downloaded"

echo ""
echo "ğŸ‰ DBot setup complete!"
echo "ğŸ“ MCP Server: Ready for @dbot commands"
echo "ğŸ”§ Use: Add DBot to your MCP-capable application"
echo ""
echo "Kill MCP server with: kill $MCP_PID"
