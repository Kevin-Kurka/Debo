import fs from 'fs-extra';\nimport path from 'path';\nimport { glob } from 'glob';\nimport { v4 as uuidv4 } from 'uuid';\nimport logger from '../logger.js';\nimport { execSync } from 'child_process';\n\n/**\n * Codebase Analyzer\n * \n * PURPOSE:\n * Analyzes existing codebases to understand structure, dependencies,\n * patterns, and creates comprehensive project index for task planning.\n * \n * FEATURES:\n * - File structure analysis\n * - Dependency mapping\n * - Code pattern detection\n * - Documentation extraction\n * - Git history analysis\n * - Technology stack identification\n * \n * TODO:\n * - None\n */\nexport class CodebaseAnalyzer {\n  constructor(taskManager) {\n    this.taskManager = taskManager;\n    this.redis = taskManager.redis;\n    this.analysisCache = new Map();\n  }\n  \n  async analyzeProject(projectPath, options = {}) {\n    const projectId = `project_${Date.now()}`;\n    const startTime = Date.now();\n    \n    logger.info(`Starting codebase analysis for: ${projectPath}`);\n    \n    try {\n      // 1. Basic project structure analysis\n      const structure = await this.analyzeProjectStructure(projectPath);\n      \n      // 2. Technology stack detection\n      const techStack = await this.detectTechnologyStack(projectPath, structure);\n      \n      // 3. Dependency analysis\n      const dependencies = await this.analyzeDependencies(projectPath, techStack);\n      \n      // 4. Code pattern analysis\n      const patterns = await this.analyzeCodePatterns(projectPath, structure, techStack);\n      \n      // 5. Documentation extraction\n      const documentation = await this.extractDocumentation(projectPath, structure);\n      \n      // 6. Git history analysis\n      const gitHistory = await this.analyzeGitHistory(projectPath);\n      \n      // 7. Quality metrics\n      const quality = await this.analyzeCodeQuality(projectPath, structure, techStack);\n      \n      // 8. Create comprehensive project index\n      const projectIndex = {\n        id: projectId,\n        path: projectPath,\n        name: path.basename(projectPath),\n        analysisTimestamp: new Date().toISOString(),\n        analysisTime: Date.now() - startTime,\n        structure,\n        techStack,\n        dependencies,\n        patterns,\n        documentation,\n        gitHistory,\n        quality,\n        metadata: {\n          totalFiles: structure.files.length,\n          totalLines: structure.totalLines,\n          languages: Object.keys(techStack.languages),\n          frameworks: techStack.frameworks.map(f => f.name)\n        }\n      };\n      \n      // Store in database\n      await this.storeProjectIndex(projectIndex);\n      \n      logger.info(`Codebase analysis completed in ${projectIndex.analysisTime}ms`);\n      \n      return projectIndex;\n      \n    } catch (error) {\n      logger.error(`Codebase analysis failed: ${error.message}`);\n      throw error;\n    }\n  }\n  \n  async analyzeProjectStructure(projectPath) {\n    const structure = {\n      root: projectPath,\n      directories: [],\n      files: [],\n      totalLines: 0,\n      fileTypes: {},\n      organizationPattern: 'unknown'\n    };\n    \n    // Get all files and directories\n    const allFiles = await glob('**/*', {\n      cwd: projectPath,\n      ignore: [\n        'node_modules/**',\n        '.git/**',\n        'dist/**',\n        'build/**',\n        'coverage/**',\n        '.nyc_output/**',\n        '**/*.log',\n        '.DS_Store'\n      ],\n      dot: true\n    });\n    \n    for (const file of allFiles) {\n      const fullPath = path.join(projectPath, file);\n      const stats = await fs.stat(fullPath);\n      \n      if (stats.isDirectory()) {\n        structure.directories.push({\n          name: file,\n          path: fullPath,\n          relativePath: file\n        });\n      } else {\n        const ext = path.extname(file).toLowerCase();\n        const fileInfo = {\n          name: path.basename(file),\n          path: fullPath,\n          relativePath: file,\n          extension: ext,\n          size: stats.size,\n          modified: stats.mtime,\n          lines: 0\n        };\n        \n        // Count lines for text files\n        if (this.isTextFile(ext)) {\n          try {\n            const content = await fs.readFile(fullPath, 'utf8');\n            fileInfo.lines = content.split('\\n').length;\n            structure.totalLines += fileInfo.lines;\n          } catch (error) {\n            // Skip files we can't read\n          }\n        }\n        \n        structure.files.push(fileInfo);\n        \n        // Track file types\n        structure.fileTypes[ext] = (structure.fileTypes[ext] || 0) + 1;\n      }\n    }\n    \n    // Determine organization pattern\n    structure.organizationPattern = this.detectOrganizationPattern(structure);\n    \n    return structure;\n  }\n  \n  isTextFile(extension) {\n    const textExtensions = [\n      '.js', '.ts', '.jsx', '.tsx', '.py', '.java', '.c', '.cpp', '.h',\n      '.cs', '.php', '.rb', '.go', '.rs', '.swift', '.kt', '.scala',\n      '.html', '.css', '.scss', '.sass', '.less', '.vue', '.svelte',\n      '.json', '.xml', '.yaml', '.yml', '.toml', '.ini', '.cfg',\n      '.md', '.txt', '.rst', '.asciidoc', '.tex',\n      '.sql', '.graphql', '.gql',\n      '.sh', '.bash', '.zsh', '.ps1', '.bat',\n      '.dockerfile', '.gitignore', '.env'\n    ];\n    \n    return textExtensions.includes(extension);\n  }\n  \n  detectOrganizationPattern(structure) {\n    const dirs = structure.directories.map(d => d.name.toLowerCase());\n    \n    // Check for common patterns\n    if (dirs.includes('src') && dirs.includes('test')) {\n      return 'src-test';\n    }\n    \n    if (dirs.includes('app') && dirs.includes('config')) {\n      return 'rails-like';\n    }\n    \n    if (dirs.includes('components') && dirs.includes('pages')) {\n      return 'react-like';\n    }\n    \n    if (dirs.includes('models') && dirs.includes('views') && dirs.includes('controllers')) {\n      return 'mvc';\n    }\n    \n    if (dirs.includes('lib') && dirs.includes('bin')) {\n      return 'unix-like';\n    }\n    \n    return 'custom';\n  }\n  \n  async detectTechnologyStack(projectPath, structure) {\n    const techStack = {\n      languages: {},\n      frameworks: [],\n      buildTools: [],\n      testingFrameworks: [],\n      databases: [],\n      deployment: []\n    };\n    \n    // Language detection based on file extensions\n    for (const [ext, count] of Object.entries(structure.fileTypes)) {\n      const language = this.extensionToLanguage(ext);\n      if (language) {\n        techStack.languages[language] = (techStack.languages[language] || 0) + count;\n      }\n    }\n    \n    // Framework detection based on package.json, requirements.txt, etc.\n    await this.detectFrameworks(projectPath, techStack);\n    \n    // Build tool detection\n    await this.detectBuildTools(projectPath, techStack);\n    \n    // Testing framework detection\n    await this.detectTestingFrameworks(projectPath, techStack);\n    \n    // Database detection\n    await this.detectDatabases(projectPath, techStack);\n    \n    return techStack;\n  }\n  \n  extensionToLanguage(ext) {\n    const mapping = {\n      '.js': 'JavaScript',\n      '.mjs': 'JavaScript',\n      '.ts': 'TypeScript',\n      '.tsx': 'TypeScript',\n      '.jsx': 'JavaScript',\n      '.py': 'Python',\n      '.java': 'Java',\n      '.c': 'C',\n      '.cpp': 'C++',\n      '.h': 'C/C++ Header',\n      '.cs': 'C#',\n      '.php': 'PHP',\n      '.rb': 'Ruby',\n      '.go': 'Go',\n      '.rs': 'Rust',\n      '.swift': 'Swift',\n      '.kt': 'Kotlin',\n      '.scala': 'Scala',\n      '.html': 'HTML',\n      '.css': 'CSS',\n      '.scss': 'SCSS',\n      '.sass': 'Sass',\n      '.less': 'Less',\n      '.vue': 'Vue',\n      '.svelte': 'Svelte'\n    };\n    \n    return mapping[ext];\n  }\n  \n  async detectFrameworks(projectPath, techStack) {\n    // Node.js frameworks\n    const packageJsonPath = path.join(projectPath, 'package.json');\n    if (await fs.pathExists(packageJsonPath)) {\n      const packageJson = await fs.readJson(packageJsonPath);\n      const allDeps = {\n        ...packageJson.dependencies,\n        ...packageJson.devDependencies\n      };\n      \n      // React ecosystem\n      if (allDeps.react) {\n        techStack.frameworks.push({ name: 'React', version: allDeps.react, type: 'frontend' });\n      }\n      if (allDeps.next) {\n        techStack.frameworks.push({ name: 'Next.js', version: allDeps.next, type: 'fullstack' });\n      }\n      if (allDeps.vue) {\n        techStack.frameworks.push({ name: 'Vue.js', version: allDeps.vue, type: 'frontend' });\n      }\n      if (allDeps.nuxt) {\n        techStack.frameworks.push({ name: 'Nuxt.js', version: allDeps.nuxt, type: 'fullstack' });\n      }\n      \n      // Backend frameworks\n      if (allDeps.express) {\n        techStack.frameworks.push({ name: 'Express.js', version: allDeps.express, type: 'backend' });\n      }\n      if (allDeps.fastify) {\n        techStack.frameworks.push({ name: 'Fastify', version: allDeps.fastify, type: 'backend' });\n      }\n      if (allDeps.koa) {\n        techStack.frameworks.push({ name: 'Koa.js', version: allDeps.koa, type: 'backend' });\n      }\n      \n      // Testing frameworks\n      if (allDeps.jest) {\n        techStack.testingFrameworks.push({ name: 'Jest', version: allDeps.jest });\n      }\n      if (allDeps.mocha) {\n        techStack.testingFrameworks.push({ name: 'Mocha', version: allDeps.mocha });\n      }\n      if (allDeps.cypress) {\n        techStack.testingFrameworks.push({ name: 'Cypress', version: allDeps.cypress });\n      }\n    }\n    \n    // Python frameworks\n    const requirementsPath = path.join(projectPath, 'requirements.txt');\n    if (await fs.pathExists(requirementsPath)) {\n      const requirements = await fs.readFile(requirementsPath, 'utf8');\n      \n      if (requirements.includes('django')) {\n        techStack.frameworks.push({ name: 'Django', type: 'backend' });\n      }\n      if (requirements.includes('flask')) {\n        techStack.frameworks.push({ name: 'Flask', type: 'backend' });\n      }\n      if (requirements.includes('fastapi')) {\n        techStack.frameworks.push({ name: 'FastAPI', type: 'backend' });\n      }\n    }\n    \n    // Check for other framework indicators\n    if (await fs.pathExists(path.join(projectPath, 'angular.json'))) {\n      techStack.frameworks.push({ name: 'Angular', type: 'frontend' });\n    }\n    \n    if (await fs.pathExists(path.join(projectPath, 'svelte.config.js'))) {\n      techStack.frameworks.push({ name: 'Svelte', type: 'frontend' });\n    }\n  }\n  \n  async detectBuildTools(projectPath, techStack) {\n    const buildFiles = {\n      'webpack.config.js': 'Webpack',\n      'vite.config.js': 'Vite',\n      'rollup.config.js': 'Rollup',\n      'gulpfile.js': 'Gulp',\n      'Gruntfile.js': 'Grunt',\n      'tsconfig.json': 'TypeScript Compiler',\n      'babel.config.js': 'Babel',\n      '.babelrc': 'Babel',\n      'Makefile': 'Make',\n      'CMakeLists.txt': 'CMake',\n      'build.gradle': 'Gradle',\n      'pom.xml': 'Maven',\n      'Cargo.toml': 'Cargo'\n    };\n    \n    for (const [file, tool] of Object.entries(buildFiles)) {\n      if (await fs.pathExists(path.join(projectPath, file))) {\n        techStack.buildTools.push(tool);\n      }\n    }\n  }\n  \n  async detectTestingFrameworks(projectPath, techStack) {\n    // Already partially handled in detectFrameworks\n    // Check for test directories and config files\n    \n    const testConfigs = {\n      'jest.config.js': 'Jest',\n      'cypress.json': 'Cypress',\n      'playwright.config.js': 'Playwright',\n      'vitest.config.js': 'Vitest',\n      'karma.conf.js': 'Karma'\n    };\n    \n    for (const [file, framework] of Object.entries(testConfigs)) {\n      if (await fs.pathExists(path.join(projectPath, file))) {\n        const existing = techStack.testingFrameworks.find(f => f.name === framework);\n        if (!existing) {\n          techStack.testingFrameworks.push({ name: framework });\n        }\n      }\n    }\n  }\n  \n  async detectDatabases(projectPath, techStack) {\n    // Check package.json for database drivers\n    const packageJsonPath = path.join(projectPath, 'package.json');\n    if (await fs.pathExists(packageJsonPath)) {\n      const packageJson = await fs.readJson(packageJsonPath);\n      const allDeps = {\n        ...packageJson.dependencies,\n        ...packageJson.devDependencies\n      };\n      \n      const dbMapping = {\n        'mongoose': 'MongoDB',\n        'mongodb': 'MongoDB',\n        'pg': 'PostgreSQL',\n        'postgres': 'PostgreSQL',\n        'mysql': 'MySQL',\n        'mysql2': 'MySQL',\n        'sqlite3': 'SQLite',\n        'redis': 'Redis',\n        'ioredis': 'Redis',\n        'prisma': 'Prisma ORM',\n        'typeorm': 'TypeORM',\n        'sequelize': 'Sequelize ORM'\n      };\n      \n      for (const [dep, db] of Object.entries(dbMapping)) {\n        if (allDeps[dep]) {\n          techStack.databases.push({ name: db, driver: dep, version: allDeps[dep] });\n        }\n      }\n    }\n    \n    // Check for database config files\n    const dbFiles = {\n      'prisma/schema.prisma': 'Prisma',\n      'migrations/': 'Database Migrations',\n      'docker-compose.yml': 'Docker Databases'\n    };\n    \n    for (const [file, type] of Object.entries(dbFiles)) {\n      if (await fs.pathExists(path.join(projectPath, file))) {\n        const existing = techStack.databases.find(db => db.name === type);\n        if (!existing && type !== 'Database Migrations') {\n          techStack.databases.push({ name: type, configFile: file });\n        }\n      }\n    }\n  }\n  \n  async analyzeDependencies(projectPath, techStack) {\n    const dependencies = {\n      direct: [],\n      dev: [],\n      peer: [],\n      vulnerabilities: [],\n      outdated: [],\n      licenses: []\n    };\n    \n    // Node.js dependencies\n    const packageJsonPath = path.join(projectPath, 'package.json');\n    if (await fs.pathExists(packageJsonPath)) {\n      const packageJson = await fs.readJson(packageJsonPath);\n      \n      // Direct dependencies\n      if (packageJson.dependencies) {\n        for (const [name, version] of Object.entries(packageJson.dependencies)) {\n          dependencies.direct.push({ name, version, type: 'npm' });\n        }\n      }\n      \n      // Dev dependencies\n      if (packageJson.devDependencies) {\n        for (const [name, version] of Object.entries(packageJson.devDependencies)) {\n          dependencies.dev.push({ name, version, type: 'npm' });\n        }\n      }\n      \n      // Peer dependencies\n      if (packageJson.peerDependencies) {\n        for (const [name, version] of Object.entries(packageJson.peerDependencies)) {\n          dependencies.peer.push({ name, version, type: 'npm' });\n        }\n      }\n    }\n    \n    // Python dependencies\n    const requirementsPath = path.join(projectPath, 'requirements.txt');\n    if (await fs.pathExists(requirementsPath)) {\n      const requirements = await fs.readFile(requirementsPath, 'utf8');\n      const lines = requirements.split('\\n').filter(line => line.trim() && !line.startsWith('#'));\n      \n      for (const line of lines) {\n        const match = line.match(/^([a-zA-Z0-9_-]+)([>=<!=]+)([0-9.]+)/);\n        if (match) {\n          dependencies.direct.push({\n            name: match[1],\n            version: match[3],\n            operator: match[2],\n            type: 'python'\n          });\n        }\n      }\n    }\n    \n    // TODO: Add vulnerability and outdated dependency checking\n    // This would integrate with npm audit, safety (Python), etc.\n    \n    return dependencies;\n  }\n  \n  async analyzeCodePatterns(projectPath, structure, techStack) {\n    const patterns = {\n      architectureStyle: 'unknown',\n      designPatterns: [],\n      codeSmells: [],\n      conventions: {},\n      complexity: {\n        averageFileSize: 0,\n        largestFiles: [],\n        cyclomaticComplexity: 'unknown'\n      }\n    };\n    \n    // Analyze architecture style\n    patterns.architectureStyle = this.detectArchitectureStyle(structure, techStack);\n    \n    // Calculate complexity metrics\n    patterns.complexity.averageFileSize = structure.totalLines / structure.files.length;\n    \n    // Find largest files\n    patterns.complexity.largestFiles = structure.files\n      .sort((a, b) => b.lines - a.lines)\n      .slice(0, 10)\n      .map(f => ({ name: f.name, lines: f.lines, path: f.relativePath }));\n    \n    // Detect naming conventions\n    patterns.conventions = this.analyzeNamingConventions(structure);\n    \n    return patterns;\n  }\n  \n  detectArchitectureStyle(structure, techStack) {\n    const dirs = structure.directories.map(d => d.name.toLowerCase());\n    const frameworks = techStack.frameworks.map(f => f.name.toLowerCase());\n    \n    // Microservices\n    if (dirs.some(d => d.includes('service')) || \n        dirs.some(d => d.includes('microservice'))) {\n      return 'microservices';\n    }\n    \n    // Layered architecture\n    if (dirs.includes('controllers') && dirs.includes('services') && dirs.includes('models')) {\n      return 'layered';\n    }\n    \n    // Clean architecture\n    if (dirs.includes('domain') && dirs.includes('infrastructure') && dirs.includes('application')) {\n      return 'clean';\n    }\n    \n    // Component-based (React, Vue)\n    if (dirs.includes('components') || frameworks.some(f => f.includes('react') || f.includes('vue'))) {\n      return 'component-based';\n    }\n    \n    // Modular\n    if (dirs.includes('modules') || dirs.includes('features')) {\n      return 'modular';\n    }\n    \n    return 'monolithic';\n  }\n  \n  analyzeNamingConventions(structure) {\n    const conventions = {\n      fileNaming: 'unknown',\n      directoryNaming: 'unknown',\n      commonPatterns: []\n    };\n    \n    // Analyze file naming\n    const fileNames = structure.files.map(f => f.name);\n    const camelCaseFiles = fileNames.filter(n => /^[a-z][a-zA-Z0-9]*\\.[a-z]+$/.test(n)).length;\n    const kebabCaseFiles = fileNames.filter(n => /^[a-z]+(-[a-z]+)*\\.[a-z]+$/.test(n)).length;\n    const snakeCaseFiles = fileNames.filter(n => /^[a-z]+(_[a-z]+)*\\.[a-z]+$/.test(n)).length;\n    \n    if (camelCaseFiles > kebabCaseFiles && camelCaseFiles > snakeCaseFiles) {\n      conventions.fileNaming = 'camelCase';\n    } else if (kebabCaseFiles > snakeCaseFiles) {\n      conventions.fileNaming = 'kebab-case';\n    } else if (snakeCaseFiles > 0) {\n      conventions.fileNaming = 'snake_case';\n    }\n    \n    // Analyze directory naming\n    const dirNames = structure.directories.map(d => path.basename(d.name));\n    const camelCaseDirs = dirNames.filter(n => /^[a-z][a-zA-Z0-9]*$/.test(n)).length;\n    const kebabCaseDirs = dirNames.filter(n => /^[a-z]+(-[a-z]+)*$/.test(n)).length;\n    \n    if (camelCaseDirs > kebabCaseDirs) {\n      conventions.directoryNaming = 'camelCase';\n    } else if (kebabCaseDirs > 0) {\n      conventions.directoryNaming = 'kebab-case';\n    }\n    \n    return conventions;\n  }\n  \n  async extractDocumentation(projectPath, structure) {\n    const documentation = {\n      readme: null,\n      apiDocs: [],\n      changelog: null,\n      license: null,\n      contributing: null,\n      codeComments: {\n        total: 0,\n        coverage: 0\n      },\n      wikis: [],\n      tutorials: []\n    };\n    \n    // Look for common documentation files\n    const docFiles = {\n      readme: ['README.md', 'readme.md', 'README.txt', 'readme.txt'],\n      changelog: ['CHANGELOG.md', 'changelog.md', 'HISTORY.md', 'history.md'],\n      license: ['LICENSE', 'LICENSE.md', 'license.md', 'MIT-LICENSE'],\n      contributing: ['CONTRIBUTING.md', 'contributing.md', 'CONTRIBUTE.md']\n    };\n    \n    for (const [type, files] of Object.entries(docFiles)) {\n      for (const file of files) {\n        const filePath = path.join(projectPath, file);\n        if (await fs.pathExists(filePath)) {\n          const content = await fs.readFile(filePath, 'utf8');\n          documentation[type] = {\n            file,\n            content: content.slice(0, 5000), // Limit content size\n            size: content.length\n          };\n          break;\n        }\n      }\n    }\n    \n    // Look for API documentation\n    const apiDocPatterns = ['docs/**/*.md', 'documentation/**/*.md', 'api/**/*.md'];\n    for (const pattern of apiDocPatterns) {\n      const files = await glob(pattern, { cwd: projectPath });\n      for (const file of files) {\n        const content = await fs.readFile(path.join(projectPath, file), 'utf8');\n        documentation.apiDocs.push({\n          file,\n          title: this.extractTitle(content),\n          size: content.length\n        });\n      }\n    }\n    \n    return documentation;\n  }\n  \n  extractTitle(content) {\n    const lines = content.split('\\n');\n    for (const line of lines) {\n      if (line.startsWith('# ')) {\n        return line.substring(2).trim();\n      }\n    }\n    return 'Untitled';\n  }\n  \n  async analyzeGitHistory(projectPath) {\n    const gitHistory = {\n      hasGit: false,\n      branches: [],\n      recentCommits: [],\n      contributors: [],\n      activity: {\n        totalCommits: 0,\n        firstCommit: null,\n        lastCommit: null\n      }\n    };\n    \n    try {\n      // Check if it's a git repository\n      if (!await fs.pathExists(path.join(projectPath, '.git'))) {\n        return gitHistory;\n      }\n      \n      gitHistory.hasGit = true;\n      \n      // Get branches\n      const branchOutput = execSync('git branch -a', { \n        cwd: projectPath, \n        encoding: 'utf8' \n      });\n      gitHistory.branches = branchOutput\n        .split('\\n')\n        .map(b => b.replace(/^[\\s*]+/, '').trim())\n        .filter(b => b && !b.startsWith('remotes/origin/HEAD'));\n      \n      // Get recent commits\n      const commitOutput = execSync(\n        'git log --oneline -10 --pretty=format:\"%h|%an|%ad|%s\" --date=short',\n        { cwd: projectPath, encoding: 'utf8' }\n      );\n      \n      gitHistory.recentCommits = commitOutput\n        .split('\\n')\n        .filter(line => line.trim())\n        .map(line => {\n          const [hash, author, date, message] = line.split('|');\n          return { hash, author, date, message };\n        });\n      \n      // Get contributors\n      const contributorOutput = execSync(\n        'git shortlog -sn',\n        { cwd: projectPath, encoding: 'utf8' }\n      );\n      \n      gitHistory.contributors = contributorOutput\n        .split('\\n')\n        .filter(line => line.trim())\n        .map(line => {\n          const match = line.match(/^\\s*(\\d+)\\s+(.+)$/);\n          if (match) {\n            return { commits: parseInt(match[1]), name: match[2] };\n          }\n          return null;\n        })\n        .filter(c => c);\n      \n      // Get activity stats\n      const totalCommits = execSync(\n        'git rev-list --count HEAD',\n        { cwd: projectPath, encoding: 'utf8' }\n      ).trim();\n      \n      gitHistory.activity.totalCommits = parseInt(totalCommits);\n      \n      if (gitHistory.recentCommits.length > 0) {\n        gitHistory.activity.lastCommit = gitHistory.recentCommits[0].date;\n      }\n      \n    } catch (error) {\n      logger.warn(`Git analysis failed: ${error.message}`);\n    }\n    \n    return gitHistory;\n  }\n  \n  async analyzeCodeQuality(projectPath, structure, techStack) {\n    const quality = {\n      metrics: {\n        linesOfCode: structure.totalLines,\n        fileCount: structure.files.length,\n        averageFileSize: Math.round(structure.totalLines / structure.files.length),\n        largestFile: Math.max(...structure.files.map(f => f.lines))\n      },\n      issues: [],\n      suggestions: [],\n      score: 0\n    };\n    \n    // Basic quality checks\n    const codeFiles = structure.files.filter(f => this.isTextFile(f.extension));\n    \n    // Check for overly large files\n    const largeFiles = codeFiles.filter(f => f.lines > 500);\n    if (largeFiles.length > 0) {\n      quality.issues.push({\n        type: 'large_files',\n        severity: 'medium',\n        count: largeFiles.length,\n        message: `${largeFiles.length} files exceed 500 lines`\n      });\n    }\n    \n    // Check for missing documentation\n    if (!structure.files.some(f => f.name.toLowerCase().includes('readme'))) {\n      quality.issues.push({\n        type: 'missing_readme',\n        severity: 'high',\n        message: 'No README file found'\n      });\n    }\n    \n    // Check for test coverage\n    const testFiles = structure.files.filter(f => \n      f.name.includes('test') || \n      f.name.includes('spec') ||\n      f.relativePath.includes('/test/') ||\n      f.relativePath.includes('/tests/')\n    );\n    \n    const testCoverage = (testFiles.length / codeFiles.length) * 100;\n    if (testCoverage < 20) {\n      quality.issues.push({\n        type: 'low_test_coverage',\n        severity: 'high',\n        coverage: testCoverage,\n        message: `Low test coverage: ${testCoverage.toFixed(1)}%`\n      });\n    }\n    \n    // Calculate quality score\n    let score = 100;\n    quality.issues.forEach(issue => {\n      if (issue.severity === 'high') score -= 20;\n      else if (issue.severity === 'medium') score -= 10;\n      else score -= 5;\n    });\n    \n    quality.score = Math.max(0, score);\n    \n    return quality;\n  }\n  \n  async storeProjectIndex(projectIndex) {\n    const projectKey = `project_index:${projectIndex.id}`;\n    \n    // Store main project data\n    await this.redis.hSet(projectKey, {\n      id: projectIndex.id,\n      name: projectIndex.name,\n      path: projectIndex.path,\n      analysisTimestamp: projectIndex.analysisTimestamp,\n      analysisTime: projectIndex.analysisTime.toString(),\n      metadata: JSON.stringify(projectIndex.metadata)\n    });\n    \n    // Store detailed analysis in separate keys for better querying\n    await this.redis.hSet(`${projectKey}:structure`, {\n      totalFiles: projectIndex.structure.files.length.toString(),\n      totalLines: projectIndex.structure.totalLines.toString(),\n      organizationPattern: projectIndex.structure.organizationPattern,\n      fileTypes: JSON.stringify(projectIndex.structure.fileTypes),\n      directories: JSON.stringify(projectIndex.structure.directories.map(d => d.name))\n    });\n    \n    await this.redis.hSet(`${projectKey}:tech_stack`, {\n      languages: JSON.stringify(projectIndex.techStack.languages),\n      frameworks: JSON.stringify(projectIndex.techStack.frameworks),\n      buildTools: JSON.stringify(projectIndex.techStack.buildTools),\n      databases: JSON.stringify(projectIndex.techStack.databases)\n    });\n    \n    await this.redis.hSet(`${projectKey}:dependencies`, {\n      direct: JSON.stringify(projectIndex.dependencies.direct),\n      dev: JSON.stringify(projectIndex.dependencies.dev),\n      total: (projectIndex.dependencies.direct.length + projectIndex.dependencies.dev.length).toString()\n    });\n    \n    await this.redis.hSet(`${projectKey}:quality`, {\n      score: projectIndex.quality.score.toString(),\n      issues: JSON.stringify(projectIndex.quality.issues),\n      linesOfCode: projectIndex.quality.metrics.linesOfCode.toString()\n    });\n    \n    // Store in project index list\n    await this.redis.sAdd('project_indexes', projectIndex.id);\n    \n    logger.info(`Project index stored: ${projectIndex.id}`);\n  }\n  \n  async getProjectIndex(projectId) {\n    const projectKey = `project_index:${projectId}`;\n    \n    const [main, structure, techStack, dependencies, quality] = await Promise.all([\n      this.redis.hGetAll(projectKey),\n      this.redis.hGetAll(`${projectKey}:structure`),\n      this.redis.hGetAll(`${projectKey}:tech_stack`),\n      this.redis.hGetAll(`${projectKey}:dependencies`),\n      this.redis.hGetAll(`${projectKey}:quality`)\n    ]);\n    \n    if (!main.id) {\n      return null;\n    }\n    \n    return {\n      ...main,\n      metadata: JSON.parse(main.metadata || '{}'),\n      structure: {\n        ...structure,\n        fileTypes: JSON.parse(structure.fileTypes || '{}'),\n        directories: JSON.parse(structure.directories || '[]')\n      },\n      techStack: {\n        languages: JSON.parse(techStack.languages || '{}'),\n        frameworks: JSON.parse(techStack.frameworks || '[]'),\n        buildTools: JSON.parse(techStack.buildTools || '[]'),\n        databases: JSON.parse(techStack.databases || '[]')\n      },\n      dependencies: {\n        direct: JSON.parse(dependencies.direct || '[]'),\n        dev: JSON.parse(dependencies.dev || '[]'),\n        total: parseInt(dependencies.total || '0')\n      },\n      quality: {\n        score: parseInt(quality.score || '0'),\n        issues: JSON.parse(quality.issues || '[]'),\n        linesOfCode: parseInt(quality.linesOfCode || '0')\n      }\n    };\n  }\n  \n  async getAllProjectIndexes() {\n    const projectIds = await this.redis.sMembers('project_indexes');\n    const projects = [];\n    \n    for (const id of projectIds) {\n      const project = await this.getProjectIndex(id);\n      if (project) {\n        projects.push(project);\n      }\n    }\n    \n    return projects.sort((a, b) => new Date(b.analysisTimestamp) - new Date(a.analysisTimestamp));\n  }\n}\n\nexport default CodebaseAnalyzer;\n